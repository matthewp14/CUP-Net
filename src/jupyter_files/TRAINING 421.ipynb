{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Feb 26 17:01:56 2020\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" IMPORTS \"\"\"\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"../\")\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.constraints import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "from binary_ops import binary_tanh as binary_tanh_op\n",
    "from binary_layers import BinaryDense, BinaryConv2D\n",
    "\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from lambda_layers import *\n",
    "from binary_ops import *\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 30, 32, 32, 1)\n",
      "(293, 30, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" FUNCTIION AND VARIABLE DEFINITIONS \"\"\"\n",
    "def binary_tanh(x):\n",
    "    return binary_tanh_op(x)\n",
    "\n",
    "H = 1.\n",
    "kernel_lr_multiplier = 'Glorot'\n",
    "\n",
    "# # nn\n",
    "batch_size = 50\n",
    "epochs = 20\n",
    "channels = 1\n",
    "img_rows = 30\n",
    "img_cols = 30\n",
    "filters = 32\n",
    "kernel_size = (32, 32)\n",
    "pool_size = (2, 2)\n",
    "hidden_units = 128\n",
    "classes = 10\n",
    "use_bias = False\n",
    "\n",
    "# # learning rate schedule\n",
    "lr_start = 1e-3\n",
    "lr_end = 1e-4\n",
    "lr_decay = (lr_end / lr_start)**(1. / epochs)\n",
    "\n",
    "# # BN\n",
    "epsilon = 1e-6\n",
    "momentum = 0.9\n",
    "\n",
    "# # dropout\n",
    "p1 = 0.25\n",
    "p2 = 0.5\n",
    "\n",
    "hdf5_dir = Path(\"../../data/hdf5/\")\n",
    "\n",
    "def read_many_hdf5(num_images):\n",
    "    \"\"\" Reads image from HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    images= []\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    file = h5py.File(hdf5_dir / f\"{num_images}_vids.h5\", \"r+\")\n",
    "\n",
    "    images = np.array(file[\"/images\"]).astype(\"float32\")\n",
    "\n",
    "    return images\n",
    "\n",
    "def np_streak(x):\n",
    "    input_dims = np.shape(x)\n",
    "    output_shape = (input_dims[0],input_dims[1],input_dims[1]+input_dims[2],input_dims[3],input_dims[4])\n",
    "    streak_tensor = np.zeros(output_shape)\n",
    "    for i in range(output_shape[0]):\n",
    "        for j in range(output_shape[1]):\n",
    "            streak_tensor[i,j,j:(output_shape[3]+j),:,:] = x[i,j,:,:,:]\n",
    "    #return streak_tensor\n",
    "    return np.sum(streak_tensor,axis=1)\n",
    "\n",
    "def mask(val,ims,mask):\n",
    "    for i in range(np.shape(val)[0]):\n",
    "        for j in range(np.shape(val)[1]):\n",
    "            val[i,j,:,:] = ims[i,j,:,:] * mask\n",
    "    return val\n",
    "\n",
    "\n",
    "\n",
    "ims = read_many_hdf5(\"russian_movie\")\n",
    "ims = np.reshape(ims,(-1,30,32,32,1))\n",
    "\n",
    "validate = ims\n",
    "\n",
    "validate = validate / 255\n",
    "#ims2 = ims2 /255\n",
    "ims = ims/255\n",
    "#X_train, X_test, y_train, y_test = train_test_split(ims, validate, test_size=(1/3), random_state=42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(ims2, validate, test_size=(1/3), random_state=42)\n",
    "\n",
    "MX_train, MX_test, My_train, My_test = train_test_split(ims,ims, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(np.shape(MX_test))\n",
    "print(np.shape(MX_train))\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',verbose=1, factor=0.5,\n",
    "                              patience=25, min_lr=0.000001)\n",
    "early_stopping = EarlyStopping(patience=50,verbose=1,restore_best_weights=True)   \n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "\n",
    "  ssim_loss = (1.0-tf.image.ssim(y_true,y_pred,1))/2.0\n",
    "  mse_loss = K.mean(K.square(y_pred-y_true))\n",
    "  #mse_loss = tf.keras.losses.mean_squared_error(y_true,y_pred)\n",
    "\n",
    "  ssim_loss = 0.5*ssim_loss\n",
    "  mse_loss = 0.5*mse_loss\n",
    "\n",
    "  return ssim_loss + mse_loss\n",
    "\n",
    "def ssim_loss(y_true,y_pred):  \n",
    "    return (1.0-tf.image.ssim(y_true,y_pred,1))/2.0\n",
    "\n",
    "def mse_loss(y_true,y_pred):\n",
    "    return K.mean(K.square(y_pred-y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "sio.savemat('russianvids.mat',{'sample':ims})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" VIDEO FUNCTIONS FOR CHECKING POST TRAINING\"\"\"\n",
    "\n",
    "def get_mask(model,l=0, save = False, filename = \"mask\"):\n",
    "    b = binarize(model.layers[l].weights[0])\n",
    "    figb,axb = plt.subplots(1,1)\n",
    "    axb.imshow(np.reshape(b,(32,32)),cmap=\"gray\")\n",
    "    \n",
    "    if save:\n",
    "        b = np.reshape(b,(32,32))\n",
    "        np.save(filename,b)\n",
    "                            \n",
    "def show_video(y_pred,y_true,num,save=False):\n",
    "    yp = np.reshape(y_pred,(-1,30,32,32))\n",
    "    yt = np.reshape(y_true,(-1,30,32,32))\n",
    "    split = np.zeros((5,32,32))\n",
    "    yp_tensor = tf.convert_to_tensor(y_pred)\n",
    "    yt_tensor = tf.convert_to_tensor(y_true)\n",
    "    ssim = np.mean(ssim_loss(yt_tensor[num],yp_tensor[num]))\n",
    "    mse = np.mean(mse_loss(yt_tensor[num],yp_tensor[num]))\n",
    "    fig,ax = plt.subplots(nrows=5,ncols=13,figsize=(21,10),sharex=True,sharey=True)\n",
    "    fig.suptitle(f'Movie: {num} MSE: {mse:.3} SSIM: {ssim:.3}')\n",
    "    for row in range(5):\n",
    "        for col in range(13):\n",
    "            if col < 6:\n",
    "                ax[row,col].imshow(yp[num][5*row+col],cmap=\"gray\")\n",
    "            elif col == 6:\n",
    "                pass\n",
    "            else:\n",
    "                ax[row,col].imshow(yt[num][5*row + (col %6)],cmap=\"gray\")\n",
    "    if save:\n",
    "        fig.savefig('test.png')\n",
    "\n",
    "def show_all_videos(videos,rows,cols):\n",
    "    yp = np.reshape(videos, (-1,30,32,32))\n",
    "    fix3,ax3 = plt.subplots(nrows=rows, ncols = cols)\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            ax3[row,col].imshow(yp[rows*row+col][3],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 30, 62, 32)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 30, 32, 32, 1)     1024      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 30, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 30, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30720)             60979200  \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 30, 32, 32, 1)     0         \n",
      "=================================================================\n",
      "Total params: 60,980,224\n",
      "Trainable params: 60,980,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 293 samples, validate on 126 samples\n",
      "Epoch 1/100\n",
      "293/293 - 7s - loss: 0.2856 - ssim_loss: 0.4803 - mse_loss: 0.0878 - val_loss: 0.2676 - val_ssim_loss: 0.4699 - val_mse_loss: 0.0652\n",
      "Epoch 2/100\n",
      "293/293 - 2s - loss: 0.2653 - ssim_loss: 0.4711 - mse_loss: 0.0587 - val_loss: 0.2686 - val_ssim_loss: 0.4702 - val_mse_loss: 0.0669\n",
      "Epoch 3/100\n",
      "293/293 - 2s - loss: 0.2635 - ssim_loss: 0.4686 - mse_loss: 0.0608 - val_loss: 0.2731 - val_ssim_loss: 0.4719 - val_mse_loss: 0.0741\n",
      "Epoch 4/100\n",
      "293/293 - 2s - loss: 0.2631 - ssim_loss: 0.4673 - mse_loss: 0.0599 - val_loss: 0.2699 - val_ssim_loss: 0.4704 - val_mse_loss: 0.0693\n",
      "Epoch 5/100\n",
      "293/293 - 2s - loss: 0.2616 - ssim_loss: 0.4652 - mse_loss: 0.0598 - val_loss: 0.2715 - val_ssim_loss: 0.4709 - val_mse_loss: 0.0720\n",
      "Epoch 6/100\n",
      "293/293 - 2s - loss: 0.2614 - ssim_loss: 0.4642 - mse_loss: 0.0566 - val_loss: 0.2666 - val_ssim_loss: 0.4689 - val_mse_loss: 0.0642\n",
      "Epoch 7/100\n",
      "293/293 - 2s - loss: 0.2596 - ssim_loss: 0.4623 - mse_loss: 0.0559 - val_loss: 0.2680 - val_ssim_loss: 0.4694 - val_mse_loss: 0.0666\n",
      "Epoch 8/100\n",
      "293/293 - 2s - loss: 0.2586 - ssim_loss: 0.4606 - mse_loss: 0.0602 - val_loss: 0.2761 - val_ssim_loss: 0.4706 - val_mse_loss: 0.0814\n",
      "Epoch 9/100\n",
      "293/293 - 2s - loss: 0.2592 - ssim_loss: 0.4607 - mse_loss: 0.0545 - val_loss: 0.2656 - val_ssim_loss: 0.4679 - val_mse_loss: 0.0632\n",
      "Epoch 10/100\n",
      "293/293 - 2s - loss: 0.2573 - ssim_loss: 0.4588 - mse_loss: 0.0521 - val_loss: 0.2654 - val_ssim_loss: 0.4676 - val_mse_loss: 0.0631\n",
      "Epoch 11/100\n",
      "293/293 - 2s - loss: 0.2566 - ssim_loss: 0.4574 - mse_loss: 0.0553 - val_loss: 0.2663 - val_ssim_loss: 0.4676 - val_mse_loss: 0.0649\n",
      "Epoch 12/100\n",
      "293/293 - 2s - loss: 0.2561 - ssim_loss: 0.4566 - mse_loss: 0.0565 - val_loss: 0.2682 - val_ssim_loss: 0.4686 - val_mse_loss: 0.0677\n",
      "Epoch 13/100\n",
      "293/293 - 2s - loss: 0.2561 - ssim_loss: 0.4562 - mse_loss: 0.0577 - val_loss: 0.2700 - val_ssim_loss: 0.4696 - val_mse_loss: 0.0702\n",
      "Epoch 14/100\n",
      "293/293 - 2s - loss: 0.2563 - ssim_loss: 0.4560 - mse_loss: 0.0570 - val_loss: 0.2694 - val_ssim_loss: 0.4692 - val_mse_loss: 0.0695\n",
      "Epoch 15/100\n",
      "293/293 - 2s - loss: 0.2567 - ssim_loss: 0.4554 - mse_loss: 0.0567 - val_loss: 0.2652 - val_ssim_loss: 0.4668 - val_mse_loss: 0.0634\n",
      "Epoch 16/100\n",
      "293/293 - 2s - loss: 0.2553 - ssim_loss: 0.4542 - mse_loss: 0.0543 - val_loss: 0.2648 - val_ssim_loss: 0.4667 - val_mse_loss: 0.0628\n",
      "Epoch 17/100\n",
      "293/293 - 2s - loss: 0.2545 - ssim_loss: 0.4531 - mse_loss: 0.0528 - val_loss: 0.2658 - val_ssim_loss: 0.4675 - val_mse_loss: 0.0640\n",
      "Epoch 18/100\n",
      "293/293 - 2s - loss: 0.2540 - ssim_loss: 0.4523 - mse_loss: 0.0556 - val_loss: 0.2677 - val_ssim_loss: 0.4681 - val_mse_loss: 0.0672\n",
      "Epoch 19/100\n",
      "293/293 - 2s - loss: 0.2545 - ssim_loss: 0.4526 - mse_loss: 0.0565 - val_loss: 0.2683 - val_ssim_loss: 0.4684 - val_mse_loss: 0.0681\n",
      "Epoch 20/100\n",
      "293/293 - 2s - loss: 0.2546 - ssim_loss: 0.4519 - mse_loss: 0.0566 - val_loss: 0.2655 - val_ssim_loss: 0.4665 - val_mse_loss: 0.0643\n",
      "Epoch 21/100\n",
      "293/293 - 2s - loss: 0.2536 - ssim_loss: 0.4511 - mse_loss: 0.0536 - val_loss: 0.2642 - val_ssim_loss: 0.4664 - val_mse_loss: 0.0618\n",
      "Epoch 22/100\n",
      "293/293 - 2s - loss: 0.2528 - ssim_loss: 0.4501 - mse_loss: 0.0568 - val_loss: 0.2672 - val_ssim_loss: 0.4670 - val_mse_loss: 0.0673\n",
      "Epoch 23/100\n",
      "293/293 - 2s - loss: 0.2540 - ssim_loss: 0.4506 - mse_loss: 0.0575 - val_loss: 0.2660 - val_ssim_loss: 0.4668 - val_mse_loss: 0.0650\n",
      "Epoch 24/100\n",
      "293/293 - 2s - loss: 0.2535 - ssim_loss: 0.4504 - mse_loss: 0.0548 - val_loss: 0.2650 - val_ssim_loss: 0.4668 - val_mse_loss: 0.0630\n",
      "Epoch 25/100\n",
      "293/293 - 2s - loss: 0.2527 - ssim_loss: 0.4493 - mse_loss: 0.0568 - val_loss: 0.2664 - val_ssim_loss: 0.4672 - val_mse_loss: 0.0655\n",
      "Epoch 26/100\n",
      "293/293 - 2s - loss: 0.2529 - ssim_loss: 0.4494 - mse_loss: 0.0542 - val_loss: 0.2646 - val_ssim_loss: 0.4663 - val_mse_loss: 0.0628\n",
      "Epoch 27/100\n",
      "293/293 - 2s - loss: 0.2520 - ssim_loss: 0.4483 - mse_loss: 0.0540 - val_loss: 0.2636 - val_ssim_loss: 0.4652 - val_mse_loss: 0.0620\n",
      "Epoch 28/100\n",
      "293/293 - 2s - loss: 0.2515 - ssim_loss: 0.4473 - mse_loss: 0.0569 - val_loss: 0.2673 - val_ssim_loss: 0.4672 - val_mse_loss: 0.0672\n",
      "Epoch 29/100\n",
      "293/293 - 2s - loss: 0.2522 - ssim_loss: 0.4478 - mse_loss: 0.0582 - val_loss: 0.2664 - val_ssim_loss: 0.4664 - val_mse_loss: 0.0662\n",
      "Epoch 30/100\n",
      "293/293 - 2s - loss: 0.2523 - ssim_loss: 0.4479 - mse_loss: 0.0581 - val_loss: 0.2673 - val_ssim_loss: 0.4668 - val_mse_loss: 0.0677\n",
      "Epoch 31/100\n",
      "293/293 - 2s - loss: 0.2526 - ssim_loss: 0.4477 - mse_loss: 0.0560 - val_loss: 0.2653 - val_ssim_loss: 0.4662 - val_mse_loss: 0.0643\n",
      "Epoch 32/100\n",
      "293/293 - 2s - loss: 0.2517 - ssim_loss: 0.4467 - mse_loss: 0.0592 - val_loss: 0.2669 - val_ssim_loss: 0.4665 - val_mse_loss: 0.0672\n",
      "Epoch 33/100\n",
      "293/293 - 2s - loss: 0.2523 - ssim_loss: 0.4475 - mse_loss: 0.0565 - val_loss: 0.2636 - val_ssim_loss: 0.4649 - val_mse_loss: 0.0621\n",
      "Epoch 34/100\n",
      "293/293 - 2s - loss: 0.2512 - ssim_loss: 0.4462 - mse_loss: 0.0574 - val_loss: 0.2656 - val_ssim_loss: 0.4659 - val_mse_loss: 0.0652\n",
      "Epoch 35/100\n",
      "293/293 - 2s - loss: 0.2516 - ssim_loss: 0.4464 - mse_loss: 0.0563 - val_loss: 0.2644 - val_ssim_loss: 0.4654 - val_mse_loss: 0.0633\n",
      "Epoch 36/100\n",
      "293/293 - 2s - loss: 0.2510 - ssim_loss: 0.4456 - mse_loss: 0.0566 - val_loss: 0.2656 - val_ssim_loss: 0.4663 - val_mse_loss: 0.0648\n",
      "Epoch 37/100\n",
      "293/293 - 2s - loss: 0.2510 - ssim_loss: 0.4457 - mse_loss: 0.0557 - val_loss: 0.2643 - val_ssim_loss: 0.4655 - val_mse_loss: 0.0630\n",
      "Epoch 38/100\n",
      "293/293 - 2s - loss: 0.2511 - ssim_loss: 0.4458 - mse_loss: 0.0536 - val_loss: 0.2625 - val_ssim_loss: 0.4640 - val_mse_loss: 0.0610\n",
      "Epoch 39/100\n",
      "293/293 - 2s - loss: 0.2502 - ssim_loss: 0.4444 - mse_loss: 0.0543 - val_loss: 0.2634 - val_ssim_loss: 0.4652 - val_mse_loss: 0.0616\n",
      "Epoch 40/100\n",
      "293/293 - 2s - loss: 0.2506 - ssim_loss: 0.4447 - mse_loss: 0.0574 - val_loss: 0.2660 - val_ssim_loss: 0.4664 - val_mse_loss: 0.0655\n",
      "Epoch 41/100\n",
      "293/293 - 2s - loss: 0.2509 - ssim_loss: 0.4450 - mse_loss: 0.0565 - val_loss: 0.2637 - val_ssim_loss: 0.4647 - val_mse_loss: 0.0626\n",
      "Epoch 42/100\n",
      "293/293 - 2s - loss: 0.2500 - ssim_loss: 0.4440 - mse_loss: 0.0563 - val_loss: 0.2644 - val_ssim_loss: 0.4654 - val_mse_loss: 0.0634\n",
      "Epoch 43/100\n",
      "293/293 - 2s - loss: 0.2506 - ssim_loss: 0.4443 - mse_loss: 0.0550 - val_loss: 0.2637 - val_ssim_loss: 0.4650 - val_mse_loss: 0.0622\n",
      "Epoch 44/100\n",
      "293/293 - 2s - loss: 0.2498 - ssim_loss: 0.4436 - mse_loss: 0.0555 - val_loss: 0.2641 - val_ssim_loss: 0.4651 - val_mse_loss: 0.0630\n",
      "Epoch 45/100\n",
      "293/293 - 2s - loss: 0.2498 - ssim_loss: 0.4436 - mse_loss: 0.0597 - val_loss: 0.2687 - val_ssim_loss: 0.4669 - val_mse_loss: 0.0704\n",
      "Epoch 46/100\n",
      "293/293 - 2s - loss: 0.2512 - ssim_loss: 0.4445 - mse_loss: 0.0573 - val_loss: 0.2638 - val_ssim_loss: 0.4647 - val_mse_loss: 0.0628\n",
      "Epoch 47/100\n",
      "293/293 - 2s - loss: 0.2498 - ssim_loss: 0.4430 - mse_loss: 0.0531 - val_loss: 0.2636 - val_ssim_loss: 0.4648 - val_mse_loss: 0.0623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "293/293 - 2s - loss: 0.2493 - ssim_loss: 0.4423 - mse_loss: 0.0570 - val_loss: 0.2646 - val_ssim_loss: 0.4650 - val_mse_loss: 0.0640\n",
      "Epoch 49/100\n",
      "293/293 - 2s - loss: 0.2495 - ssim_loss: 0.4425 - mse_loss: 0.0577 - val_loss: 0.2649 - val_ssim_loss: 0.4649 - val_mse_loss: 0.0647\n",
      "Epoch 50/100\n",
      "293/293 - 2s - loss: 0.2496 - ssim_loss: 0.4424 - mse_loss: 0.0586 - val_loss: 0.2651 - val_ssim_loss: 0.4653 - val_mse_loss: 0.0648\n",
      "Epoch 51/100\n",
      "293/293 - 2s - loss: 0.2499 - ssim_loss: 0.4430 - mse_loss: 0.0557 - val_loss: 0.2629 - val_ssim_loss: 0.4642 - val_mse_loss: 0.0614\n",
      "Epoch 52/100\n",
      "293/293 - 2s - loss: 0.2491 - ssim_loss: 0.4421 - mse_loss: 0.0552 - val_loss: 0.2627 - val_ssim_loss: 0.4637 - val_mse_loss: 0.0617\n",
      "Epoch 53/100\n",
      "293/293 - 2s - loss: 0.2489 - ssim_loss: 0.4416 - mse_loss: 0.0537 - val_loss: 0.2625 - val_ssim_loss: 0.4639 - val_mse_loss: 0.0610\n",
      "Epoch 54/100\n",
      "293/293 - 2s - loss: 0.2484 - ssim_loss: 0.4408 - mse_loss: 0.0532 - val_loss: 0.2611 - val_ssim_loss: 0.4625 - val_mse_loss: 0.0596\n",
      "Epoch 55/100\n",
      "293/293 - 2s - loss: 0.2477 - ssim_loss: 0.4396 - mse_loss: 0.0545 - val_loss: 0.2638 - val_ssim_loss: 0.4649 - val_mse_loss: 0.0627\n",
      "Epoch 56/100\n",
      "293/293 - 2s - loss: 0.2484 - ssim_loss: 0.4405 - mse_loss: 0.0552 - val_loss: 0.2652 - val_ssim_loss: 0.4656 - val_mse_loss: 0.0647\n",
      "Epoch 57/100\n",
      "293/293 - 2s - loss: 0.2489 - ssim_loss: 0.4412 - mse_loss: 0.0544 - val_loss: 0.2632 - val_ssim_loss: 0.4645 - val_mse_loss: 0.0619\n",
      "Epoch 58/100\n",
      "293/293 - 2s - loss: 0.2480 - ssim_loss: 0.4402 - mse_loss: 0.0572 - val_loss: 0.2653 - val_ssim_loss: 0.4658 - val_mse_loss: 0.0647\n",
      "Epoch 59/100\n",
      "293/293 - 2s - loss: 0.2489 - ssim_loss: 0.4413 - mse_loss: 0.0568 - val_loss: 0.2629 - val_ssim_loss: 0.4636 - val_mse_loss: 0.0620\n",
      "Epoch 60/100\n",
      "293/293 - 2s - loss: 0.2481 - ssim_loss: 0.4398 - mse_loss: 0.0527 - val_loss: 0.2635 - val_ssim_loss: 0.4647 - val_mse_loss: 0.0623\n",
      "Epoch 61/100\n",
      "293/293 - 2s - loss: 0.2481 - ssim_loss: 0.4399 - mse_loss: 0.0559 - val_loss: 0.2642 - val_ssim_loss: 0.4652 - val_mse_loss: 0.0631\n",
      "Epoch 62/100\n",
      "293/293 - 2s - loss: 0.2483 - ssim_loss: 0.4406 - mse_loss: 0.0551 - val_loss: 0.2625 - val_ssim_loss: 0.4640 - val_mse_loss: 0.0610\n",
      "Epoch 63/100\n",
      "293/293 - 2s - loss: 0.2480 - ssim_loss: 0.4398 - mse_loss: 0.0562 - val_loss: 0.2628 - val_ssim_loss: 0.4641 - val_mse_loss: 0.0614\n",
      "Epoch 64/100\n",
      "293/293 - 2s - loss: 0.2478 - ssim_loss: 0.4396 - mse_loss: 0.0543 - val_loss: 0.2623 - val_ssim_loss: 0.4637 - val_mse_loss: 0.0608\n",
      "Epoch 65/100\n",
      "293/293 - 2s - loss: 0.2477 - ssim_loss: 0.4395 - mse_loss: 0.0560 - val_loss: 0.2633 - val_ssim_loss: 0.4642 - val_mse_loss: 0.0623\n",
      "Epoch 66/100\n",
      "293/293 - 2s - loss: 0.2476 - ssim_loss: 0.4389 - mse_loss: 0.0572 - val_loss: 0.2646 - val_ssim_loss: 0.4640 - val_mse_loss: 0.0650\n",
      "Epoch 67/100\n",
      "293/293 - 2s - loss: 0.2476 - ssim_loss: 0.4387 - mse_loss: 0.0543 - val_loss: 0.2614 - val_ssim_loss: 0.4629 - val_mse_loss: 0.0598\n",
      "Epoch 68/100\n",
      "293/293 - 2s - loss: 0.2473 - ssim_loss: 0.4386 - mse_loss: 0.0570 - val_loss: 0.2633 - val_ssim_loss: 0.4642 - val_mse_loss: 0.0622\n",
      "Epoch 69/100\n",
      "293/293 - 2s - loss: 0.2477 - ssim_loss: 0.4388 - mse_loss: 0.0579 - val_loss: 0.2650 - val_ssim_loss: 0.4653 - val_mse_loss: 0.0645\n",
      "Epoch 70/100\n",
      "293/293 - 2s - loss: 0.2480 - ssim_loss: 0.4391 - mse_loss: 0.0547 - val_loss: 0.2628 - val_ssim_loss: 0.4638 - val_mse_loss: 0.0618\n",
      "Epoch 71/100\n",
      "293/293 - 2s - loss: 0.2476 - ssim_loss: 0.4385 - mse_loss: 0.0529 - val_loss: 0.2620 - val_ssim_loss: 0.4631 - val_mse_loss: 0.0609\n",
      "Epoch 72/100\n",
      "293/293 - 2s - loss: 0.2469 - ssim_loss: 0.4378 - mse_loss: 0.0599 - val_loss: 0.2654 - val_ssim_loss: 0.4647 - val_mse_loss: 0.0659\n",
      "Epoch 73/100\n",
      "293/293 - 2s - loss: 0.2478 - ssim_loss: 0.4385 - mse_loss: 0.0587 - val_loss: 0.2643 - val_ssim_loss: 0.4643 - val_mse_loss: 0.0641\n",
      "Epoch 74/100\n",
      "293/293 - 2s - loss: 0.2480 - ssim_loss: 0.4385 - mse_loss: 0.0568 - val_loss: 0.2621 - val_ssim_loss: 0.4632 - val_mse_loss: 0.0609\n",
      "Epoch 75/100\n",
      "293/293 - 2s - loss: 0.2468 - ssim_loss: 0.4373 - mse_loss: 0.0537 - val_loss: 0.2619 - val_ssim_loss: 0.4629 - val_mse_loss: 0.0609\n",
      "Epoch 76/100\n",
      "293/293 - 2s - loss: 0.2468 - ssim_loss: 0.4372 - mse_loss: 0.0550 - val_loss: 0.2619 - val_ssim_loss: 0.4630 - val_mse_loss: 0.0607\n",
      "Epoch 77/100\n",
      "293/293 - 2s - loss: 0.2467 - ssim_loss: 0.4370 - mse_loss: 0.0561 - val_loss: 0.2625 - val_ssim_loss: 0.4633 - val_mse_loss: 0.0617\n",
      "Epoch 78/100\n",
      "293/293 - 2s - loss: 0.2467 - ssim_loss: 0.4370 - mse_loss: 0.0574 - val_loss: 0.2635 - val_ssim_loss: 0.4637 - val_mse_loss: 0.0632\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "293/293 - 2s - loss: 0.2470 - ssim_loss: 0.4372 - mse_loss: 0.0577 - val_loss: 0.2632 - val_ssim_loss: 0.4635 - val_mse_loss: 0.0629\n",
      "Epoch 80/100\n",
      "293/293 - 2s - loss: 0.2444 - ssim_loss: 0.4333 - mse_loss: 0.0568 - val_loss: 0.2584 - val_ssim_loss: 0.4594 - val_mse_loss: 0.0574\n",
      "Epoch 81/100\n",
      "293/293 - 2s - loss: 0.2426 - ssim_loss: 0.4307 - mse_loss: 0.0511 - val_loss: 0.2577 - val_ssim_loss: 0.4587 - val_mse_loss: 0.0566\n",
      "Epoch 82/100\n",
      "293/293 - 2s - loss: 0.2422 - ssim_loss: 0.4301 - mse_loss: 0.0566 - val_loss: 0.2587 - val_ssim_loss: 0.4597 - val_mse_loss: 0.0576\n",
      "Epoch 83/100\n",
      "293/293 - 2s - loss: 0.2423 - ssim_loss: 0.4303 - mse_loss: 0.0550 - val_loss: 0.2584 - val_ssim_loss: 0.4594 - val_mse_loss: 0.0573\n",
      "Epoch 84/100\n",
      "293/293 - 2s - loss: 0.2421 - ssim_loss: 0.4300 - mse_loss: 0.0558 - val_loss: 0.2581 - val_ssim_loss: 0.4591 - val_mse_loss: 0.0570\n",
      "Epoch 85/100\n",
      "293/293 - 2s - loss: 0.2419 - ssim_loss: 0.4297 - mse_loss: 0.0531 - val_loss: 0.2578 - val_ssim_loss: 0.4588 - val_mse_loss: 0.0568\n",
      "Epoch 86/100\n",
      "293/293 - 2s - loss: 0.2417 - ssim_loss: 0.4293 - mse_loss: 0.0539 - val_loss: 0.2583 - val_ssim_loss: 0.4593 - val_mse_loss: 0.0572\n",
      "Epoch 87/100\n",
      "293/293 - 2s - loss: 0.2417 - ssim_loss: 0.4294 - mse_loss: 0.0577 - val_loss: 0.2582 - val_ssim_loss: 0.4591 - val_mse_loss: 0.0573\n",
      "Epoch 88/100\n",
      "293/293 - 2s - loss: 0.2417 - ssim_loss: 0.4292 - mse_loss: 0.0556 - val_loss: 0.2579 - val_ssim_loss: 0.4588 - val_mse_loss: 0.0569\n",
      "Epoch 89/100\n",
      "293/293 - 2s - loss: 0.2414 - ssim_loss: 0.4288 - mse_loss: 0.0546 - val_loss: 0.2584 - val_ssim_loss: 0.4594 - val_mse_loss: 0.0574\n",
      "Epoch 90/100\n",
      "293/293 - 2s - loss: 0.2415 - ssim_loss: 0.4289 - mse_loss: 0.0565 - val_loss: 0.2580 - val_ssim_loss: 0.4588 - val_mse_loss: 0.0571\n",
      "Epoch 91/100\n",
      "293/293 - 2s - loss: 0.2412 - ssim_loss: 0.4285 - mse_loss: 0.0551 - val_loss: 0.2580 - val_ssim_loss: 0.4589 - val_mse_loss: 0.0570\n",
      "Epoch 92/100\n",
      "293/293 - 2s - loss: 0.2412 - ssim_loss: 0.4286 - mse_loss: 0.0537 - val_loss: 0.2585 - val_ssim_loss: 0.4596 - val_mse_loss: 0.0572\n",
      "Epoch 93/100\n",
      "293/293 - 2s - loss: 0.2414 - ssim_loss: 0.4288 - mse_loss: 0.0532 - val_loss: 0.2577 - val_ssim_loss: 0.4586 - val_mse_loss: 0.0567\n",
      "Epoch 94/100\n",
      "293/293 - 2s - loss: 0.2410 - ssim_loss: 0.4281 - mse_loss: 0.0547 - val_loss: 0.2577 - val_ssim_loss: 0.4586 - val_mse_loss: 0.0568\n",
      "Epoch 95/100\n",
      "293/293 - 2s - loss: 0.2409 - ssim_loss: 0.4280 - mse_loss: 0.0528 - val_loss: 0.2576 - val_ssim_loss: 0.4585 - val_mse_loss: 0.0565\n",
      "Epoch 96/100\n",
      "293/293 - 2s - loss: 0.2407 - ssim_loss: 0.4276 - mse_loss: 0.0541 - val_loss: 0.2578 - val_ssim_loss: 0.4586 - val_mse_loss: 0.0569\n",
      "Epoch 97/100\n",
      "293/293 - 2s - loss: 0.2407 - ssim_loss: 0.4276 - mse_loss: 0.0552 - val_loss: 0.2580 - val_ssim_loss: 0.4589 - val_mse_loss: 0.0570\n",
      "Epoch 98/100\n",
      "293/293 - 2s - loss: 0.2407 - ssim_loss: 0.4276 - mse_loss: 0.0542 - val_loss: 0.2578 - val_ssim_loss: 0.4588 - val_mse_loss: 0.0568\n",
      "Epoch 99/100\n",
      "293/293 - 2s - loss: 0.2405 - ssim_loss: 0.4274 - mse_loss: 0.0520 - val_loss: 0.2576 - val_ssim_loss: 0.4585 - val_mse_loss: 0.0566\n",
      "Epoch 100/100\n",
      "293/293 - 2s - loss: 0.2404 - ssim_loss: 0.4272 - mse_loss: 0.0517 - val_loss: 0.2575 - val_ssim_loss: 0.4584 - val_mse_loss: 0.0565\n"
     ]
    }
   ],
   "source": [
    "\"\"\" FORWARD MODEL \"\"\"\n",
    "\n",
    "forward_model = Sequential()\n",
    "forward_model.add(Input(shape=(30,32,32,1)))\n",
    "forward_model.add(TimeDistributed(BinaryConv2D(1, kernel_size=(32,32), input_shape=(30,32,32,1),\n",
    "                   data_format='channels_last',\n",
    "                   H=H, kernel_lr_multiplier=kernel_lr_multiplier,\n",
    "                   padding='same', use_bias=use_bias, name='bin_conv_1')))\n",
    "forward_model.add(Reshape((30,32,32)))\n",
    "forward_model.add(Lambda(streak,output_shape=streak_output_shape))\n",
    "forward_model.add(Lambda(integrate_ims, output_shape = integrate_ims_output_shape))\n",
    "forward_model.add(Flatten())\n",
    "forward_model.add(Dense(30720, activation = 'relu'))\n",
    "forward_model.add(Reshape((30,32,32,1)))\n",
    "forward_model.compile(optimizer = Nadam(0.0001), loss = custom_loss, metrics = [ssim_loss,mse_loss])\n",
    "forward_model.summary()\n",
    "forward_history = forward_model.fit(MX_train, My_train,\n",
    "      batch_size = 32,epochs= 100,\n",
    "      verbose=2,validation_data=(MX_test,My_test),callbacks=[reduce_lr, early_stopping])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_forward = forward_model.predict(MX_test)\n",
    "show_video(y_pred_forward,MX_test,53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_model.save_weights(\"../../data/model_stuff/forward_model_weights_4_22.h5\")\n",
    "binary_weights = forward_model.layers[0].get_weights()\n",
    "inverse_weights = forward_model.layers[5].get_weights()\n",
    "get_mask(forward_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_model.load_weights(\"../../data/model_stuff/forward_model_weights_4_22.h5\")\n",
    "binary_weights = forward_model.layers[0].get_weights()\n",
    "inverse_weights = forward_model.layers[5].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mask(forward_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.load(\"test.npy\")\n",
    "plt.imshow(z)\n",
    "get_mask(forward_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 30, 32, 32,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 30, 32, 32, 1 1024        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 30, 32, 32)   0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 30, 62, 32)   0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 62, 32)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1984)         0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30720)        60979200    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 30, 32, 32, 1 0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 30, 32, 32, 1 10          reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 32, 32, 1 0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 30, 32, 32, 1 160         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 30, 16, 16, 1 0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 30, 16, 16, 3 4640        time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 16, 16, 3 0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 30, 16, 16, 3 9248        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 30, 8, 8, 32) 0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 30, 8, 8, 64) 18496       time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 30, 8, 8, 64) 0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 30, 8, 8, 64) 36928       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 30, 4, 4, 64) 0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 30, 4, 4, 128 73856       time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 4, 4, 128 0           time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 30, 4, 4, 128 147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 30, 2, 2, 128 0           time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 30, 2, 2, 256 131328      time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 30, 2, 2, 256 0           time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 30, 2, 2, 256 262400      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 30, 4, 4, 128 295040      time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 4, 4, 256 0           time_distributed_16[0][0]        \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, 30, 4, 4, 128 295040      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 30, 4, 4, 128 0           time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, 30, 4, 4, 128 147584      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, 30, 8, 8, 64) 73792       time_distributed_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 8, 8, 128 0           time_distributed_19[0][0]        \n",
      "                                                                 time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_20 (TimeDistri (None, 30, 8, 8, 64) 73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 30, 8, 8, 64) 0           time_distributed_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, 30, 8, 8, 64) 36928       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, 30, 16, 16, 3 18464       time_distributed_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 30, 16, 16, 6 0           time_distributed_22[0][0]        \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, 30, 16, 16, 3 18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 30, 16, 16, 3 0           time_distributed_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, 30, 16, 16, 3 9248        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_25 (TimeDistri (None, 30, 32, 32, 1 4624        time_distributed_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_26 (TimeDistri (None, 30, 32, 32, 1 2320        time_distributed_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 30, 32, 32, 1 0           time_distributed_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_27 (TimeDistri (None, 30, 32, 32, 1 2320        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_28 (TimeDistri (None, 30, 32, 32, 1 17          time_distributed_27[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 62,642,507\n",
      "Trainable params: 1,662,283\n",
      "Non-trainable params: 60,980,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "UNET MODEL\n",
    "Fixing the weights for the bin_conv1 layer as well as the dense1 layer, ie NON TRAINABLE\n",
    "Feeding in weights from the forward_model above to see if that improves the results from previous session\n",
    "\n",
    "\"\"\"\n",
    "inputs = Input(shape=(30,32,32,1))\n",
    "bin_conv1 = TimeDistributed(BinaryConv2D(1, kernel_size=(32,32), input_shape=(30,32,32,1),\n",
    "                       data_format='channels_last',\n",
    "                       H=H, kernel_lr_multiplier=kernel_lr_multiplier,\n",
    "                       padding='same', use_bias=use_bias, name='bin_conv_1',trainable=False))(inputs)\n",
    "resh1 = Reshape((30,32,32))(bin_conv1)\n",
    "s = Lambda(streak, output_shape = streak_output_shape)(resh1)\n",
    "i = Lambda(integrate_ims, output_shape = integrate_ims_output_shape) (s)\n",
    "f = Flatten()(i)\n",
    "dense1 = Dense(30720, activation = 'relu',trainable=False)(f)\n",
    "resh2 = Reshape((30,32,32,1))(dense1)\n",
    "c1 = TimeDistributed(Conv2D(1, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')) (resh2)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = TimeDistributed(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') )(c1)\n",
    "p1 = TimeDistributed(MaxPooling2D((2, 2)))(c1)\n",
    "\n",
    "c2 = TimeDistributed(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = TimeDistributed(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') )(c2)\n",
    "p2 = TimeDistributed(MaxPooling2D((2, 2)) )(c2)\n",
    "\n",
    "c3 = TimeDistributed(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') )(p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = TimeDistributed(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') )(c3)\n",
    "p3 = TimeDistributed(MaxPooling2D((2, 2)) )(c3)\n",
    "    \n",
    "c4 = TimeDistributed(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') )(p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = TimeDistributed(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') )(c4)\n",
    "p4 = TimeDistributed(MaxPooling2D(pool_size=(2, 2))) (c4)\n",
    "\n",
    "c5 = TimeDistributed(Conv2D(256, (2, 2), activation='relu', kernel_initializer='he_normal', padding='same')) (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = TimeDistributed(Conv2D(256, (2, 2), activation='relu', kernel_initializer='he_normal', padding='same')) (c5)\n",
    "\n",
    "u6 = TimeDistributed(Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same'))(c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = TimeDistributed( Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') )(u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = TimeDistributed(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')) (c6)\n",
    "\n",
    "u7 = TimeDistributed(Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same') )(c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = TimeDistributed(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')) (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = TimeDistributed(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')) (c7)\n",
    "    \n",
    "u8 = TimeDistributed(Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same') )(c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = TimeDistributed(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')) (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = TimeDistributed(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')) (c8)\n",
    "\n",
    "u9 = TimeDistributed(Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same')) (c8)\n",
    "c9 = TimeDistributed(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')) (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = TimeDistributed(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')) (c9)\n",
    "    \n",
    "outputs = TimeDistributed(Conv2D(1, (1, 1), activation='sigmoid')) (c9)\n",
    "\n",
    "CUPNET = Model(inputs = [inputs], outputs = [outputs])\n",
    "    \n",
    "CUPNET.compile(optimizer = Nadam(), loss = custom_loss, metrics = ['mean_squared_error'],callbacks=[reduce_lr, early_stopping])\n",
    "CUPNET.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUPNET_test = Model(inputs = [inputs], outputs = [outputs])\n",
    "\n",
    "CUPNET_test.compile(optimizer = Nadam(), loss = custom_loss, metrics = ['mean_squared_error'],callbacks=[reduce_lr, early_stopping])\n",
    "CUPNET_test.load_weights(\"../../data/model_stuff/cupnet_model_weights_4_22.h5\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = CUPNET_test.predict(MX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 30, 32, 32,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 30, 32, 32, 1 1024        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 30, 32, 32)   0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 30, 62, 32)   0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 62, 32)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1984)         0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30720)        60979200    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 30, 32, 32, 1 0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 30, 32, 32, 1 10          reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 32, 32, 1 0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 30, 32, 32, 1 160         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 30, 16, 16, 1 0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 30, 16, 16, 3 4640        time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 16, 16, 3 0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 30, 16, 16, 3 9248        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 30, 8, 8, 32) 0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 30, 8, 8, 64) 18496       time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 30, 8, 8, 64) 0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 30, 8, 8, 64) 36928       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 30, 4, 4, 64) 0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 30, 4, 4, 128 73856       time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 4, 4, 128 0           time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 30, 4, 4, 128 147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 30, 2, 2, 128 0           time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 30, 2, 2, 256 131328      time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 30, 2, 2, 256 0           time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 30, 2, 2, 256 262400      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 30, 4, 4, 128 295040      time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 4, 4, 256 0           time_distributed_16[0][0]        \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, 30, 4, 4, 128 295040      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 30, 4, 4, 128 0           time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, 30, 4, 4, 128 147584      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, 30, 8, 8, 64) 73792       time_distributed_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 8, 8, 128 0           time_distributed_19[0][0]        \n",
      "                                                                 time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_20 (TimeDistri (None, 30, 8, 8, 64) 73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 30, 8, 8, 64) 0           time_distributed_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, 30, 8, 8, 64) 36928       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, 30, 16, 16, 3 18464       time_distributed_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 30, 16, 16, 6 0           time_distributed_22[0][0]        \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, 30, 16, 16, 3 18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 30, 16, 16, 3 0           time_distributed_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, 30, 16, 16, 3 9248        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_25 (TimeDistri (None, 30, 32, 32, 1 4624        time_distributed_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_26 (TimeDistri (None, 30, 32, 32, 1 2320        time_distributed_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 30, 32, 32, 1 0           time_distributed_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_27 (TimeDistri (None, 30, 32, 32, 1 2320        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_28 (TimeDistri (None, 30, 32, 32, 1 17          time_distributed_27[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 62,642,507\n",
      "Trainable params: 1,662,283\n",
      "Non-trainable params: 60,980,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CUPNET.layers[1].set_weights(binary_weights)\n",
    "CUPNET.layers[6].set_weights(inverse_weights)\n",
    "CUPNET.summary()\n",
    "get_mask(CUPNET,l=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1412 samples, validate on 606 samples\n",
      "Epoch 1/150\n",
      "1412/1412 - 36s - loss: 0.1947 - mean_squared_error: 0.0473 - val_loss: 0.1684 - val_mean_squared_error: 0.0257\n",
      "Epoch 2/150\n",
      "1412/1412 - 20s - loss: 0.1621 - mean_squared_error: 0.0208 - val_loss: 0.1580 - val_mean_squared_error: 0.0196\n",
      "Epoch 3/150\n",
      "1412/1412 - 20s - loss: 0.1532 - mean_squared_error: 0.0181 - val_loss: 0.1643 - val_mean_squared_error: 0.0241\n",
      "Epoch 4/150\n",
      "1412/1412 - 20s - loss: 0.1490 - mean_squared_error: 0.0172 - val_loss: 0.1548 - val_mean_squared_error: 0.0212\n",
      "Epoch 5/150\n",
      "1412/1412 - 20s - loss: 0.1434 - mean_squared_error: 0.0157 - val_loss: 0.1523 - val_mean_squared_error: 0.0197\n",
      "Epoch 6/150\n",
      "1412/1412 - 20s - loss: 0.1401 - mean_squared_error: 0.0152 - val_loss: 0.1486 - val_mean_squared_error: 0.0169\n",
      "Epoch 7/150\n",
      "1412/1412 - 20s - loss: 0.1366 - mean_squared_error: 0.0142 - val_loss: 0.1459 - val_mean_squared_error: 0.0160\n",
      "Epoch 8/150\n",
      "1412/1412 - 20s - loss: 0.1346 - mean_squared_error: 0.0139 - val_loss: 0.1568 - val_mean_squared_error: 0.0222\n",
      "Epoch 9/150\n",
      "1412/1412 - 20s - loss: 0.1331 - mean_squared_error: 0.0137 - val_loss: 0.1472 - val_mean_squared_error: 0.0174\n",
      "Epoch 10/150\n",
      "1412/1412 - 20s - loss: 0.1319 - mean_squared_error: 0.0135 - val_loss: 0.1496 - val_mean_squared_error: 0.0172\n",
      "Epoch 11/150\n",
      "1412/1412 - 20s - loss: 0.1303 - mean_squared_error: 0.0132 - val_loss: 0.1438 - val_mean_squared_error: 0.0154\n",
      "Epoch 12/150\n",
      "1412/1412 - 20s - loss: 0.1293 - mean_squared_error: 0.0131 - val_loss: 0.1434 - val_mean_squared_error: 0.0154\n",
      "Epoch 13/150\n",
      "1412/1412 - 20s - loss: 0.1283 - mean_squared_error: 0.0128 - val_loss: 0.1415 - val_mean_squared_error: 0.0149\n",
      "Epoch 14/150\n",
      "1412/1412 - 20s - loss: 0.1283 - mean_squared_error: 0.0131 - val_loss: 0.1486 - val_mean_squared_error: 0.0176\n",
      "Epoch 15/150\n",
      "1412/1412 - 20s - loss: 0.1269 - mean_squared_error: 0.0125 - val_loss: 0.1463 - val_mean_squared_error: 0.0160\n",
      "Epoch 16/150\n",
      "1412/1412 - 20s - loss: 0.1263 - mean_squared_error: 0.0127 - val_loss: 0.1442 - val_mean_squared_error: 0.0177\n",
      "Epoch 17/150\n",
      "1412/1412 - 20s - loss: 0.1260 - mean_squared_error: 0.0126 - val_loss: 0.1413 - val_mean_squared_error: 0.0159\n",
      "Epoch 18/150\n",
      "1412/1412 - 20s - loss: 0.1240 - mean_squared_error: 0.0120 - val_loss: 0.1499 - val_mean_squared_error: 0.0184\n",
      "Epoch 19/150\n",
      "1412/1412 - 20s - loss: 0.1246 - mean_squared_error: 0.0123 - val_loss: 0.1401 - val_mean_squared_error: 0.0152\n",
      "Epoch 20/150\n",
      "1412/1412 - 20s - loss: 0.1235 - mean_squared_error: 0.0123 - val_loss: 0.1424 - val_mean_squared_error: 0.0158\n",
      "Epoch 21/150\n",
      "1412/1412 - 20s - loss: 0.1229 - mean_squared_error: 0.0121 - val_loss: 0.1388 - val_mean_squared_error: 0.0143\n",
      "Epoch 22/150\n",
      "1412/1412 - 20s - loss: 0.1221 - mean_squared_error: 0.0120 - val_loss: 0.1526 - val_mean_squared_error: 0.0192\n",
      "Epoch 23/150\n",
      "1412/1412 - 20s - loss: 0.1219 - mean_squared_error: 0.0120 - val_loss: 0.1400 - val_mean_squared_error: 0.0153\n",
      "Epoch 24/150\n",
      "1412/1412 - 20s - loss: 0.1210 - mean_squared_error: 0.0118 - val_loss: 0.1438 - val_mean_squared_error: 0.0169\n",
      "Epoch 25/150\n",
      "1412/1412 - 20s - loss: 0.1209 - mean_squared_error: 0.0120 - val_loss: 0.1410 - val_mean_squared_error: 0.0149\n",
      "Epoch 26/150\n",
      "1412/1412 - 20s - loss: 0.1206 - mean_squared_error: 0.0118 - val_loss: 0.1456 - val_mean_squared_error: 0.0157\n",
      "Epoch 27/150\n",
      "1412/1412 - 20s - loss: 0.1200 - mean_squared_error: 0.0118 - val_loss: 0.1448 - val_mean_squared_error: 0.0190\n",
      "Epoch 28/150\n",
      "1412/1412 - 20s - loss: 0.1195 - mean_squared_error: 0.0119 - val_loss: 0.1392 - val_mean_squared_error: 0.0148\n",
      "Epoch 29/150\n",
      "1412/1412 - 20s - loss: 0.1190 - mean_squared_error: 0.0117 - val_loss: 0.1507 - val_mean_squared_error: 0.0183\n",
      "Epoch 30/150\n",
      "1412/1412 - 20s - loss: 0.1205 - mean_squared_error: 0.0119 - val_loss: 0.1415 - val_mean_squared_error: 0.0168\n",
      "Epoch 31/150\n",
      "1412/1412 - 20s - loss: 0.1183 - mean_squared_error: 0.0116 - val_loss: 0.1406 - val_mean_squared_error: 0.0160\n",
      "Epoch 32/150\n",
      "1412/1412 - 20s - loss: 0.1177 - mean_squared_error: 0.0115 - val_loss: 0.1389 - val_mean_squared_error: 0.0147\n",
      "Epoch 33/150\n",
      "1412/1412 - 20s - loss: 0.1173 - mean_squared_error: 0.0115 - val_loss: 0.1404 - val_mean_squared_error: 0.0161\n",
      "Epoch 34/150\n",
      "1412/1412 - 20s - loss: 0.1172 - mean_squared_error: 0.0115 - val_loss: 0.1408 - val_mean_squared_error: 0.0170\n",
      "Epoch 35/150\n",
      "1412/1412 - 20s - loss: 0.1165 - mean_squared_error: 0.0114 - val_loss: 0.1409 - val_mean_squared_error: 0.0144\n",
      "Epoch 36/150\n",
      "1412/1412 - 20s - loss: 0.1160 - mean_squared_error: 0.0114 - val_loss: 0.1375 - val_mean_squared_error: 0.0145\n",
      "Epoch 37/150\n",
      "1412/1412 - 20s - loss: 0.1159 - mean_squared_error: 0.0114 - val_loss: 0.1453 - val_mean_squared_error: 0.0178\n",
      "Epoch 38/150\n",
      "1412/1412 - 20s - loss: 0.1160 - mean_squared_error: 0.0113 - val_loss: 0.1392 - val_mean_squared_error: 0.0158\n",
      "Epoch 39/150\n",
      "1412/1412 - 20s - loss: 0.1153 - mean_squared_error: 0.0113 - val_loss: 0.1480 - val_mean_squared_error: 0.0210\n",
      "Epoch 40/150\n",
      "1412/1412 - 20s - loss: 0.1144 - mean_squared_error: 0.0111 - val_loss: 0.1379 - val_mean_squared_error: 0.0150\n",
      "Epoch 41/150\n",
      "1412/1412 - 20s - loss: 0.1142 - mean_squared_error: 0.0111 - val_loss: 0.1443 - val_mean_squared_error: 0.0194\n",
      "Epoch 42/150\n",
      "1412/1412 - 20s - loss: 0.1139 - mean_squared_error: 0.0111 - val_loss: 0.1418 - val_mean_squared_error: 0.0158\n",
      "Epoch 43/150\n",
      "1412/1412 - 20s - loss: 0.1144 - mean_squared_error: 0.0112 - val_loss: 0.1367 - val_mean_squared_error: 0.0146\n",
      "Epoch 44/150\n",
      "1412/1412 - 20s - loss: 0.1138 - mean_squared_error: 0.0111 - val_loss: 0.1448 - val_mean_squared_error: 0.0193\n",
      "Epoch 45/150\n",
      "1412/1412 - 20s - loss: 0.1132 - mean_squared_error: 0.0110 - val_loss: 0.1367 - val_mean_squared_error: 0.0143\n",
      "Epoch 46/150\n",
      "1412/1412 - 20s - loss: 0.1127 - mean_squared_error: 0.0109 - val_loss: 0.1444 - val_mean_squared_error: 0.0195\n",
      "Epoch 47/150\n",
      "1412/1412 - 20s - loss: 0.1129 - mean_squared_error: 0.0111 - val_loss: 0.1378 - val_mean_squared_error: 0.0143\n",
      "Epoch 48/150\n",
      "1412/1412 - 20s - loss: 0.1123 - mean_squared_error: 0.0110 - val_loss: 0.1430 - val_mean_squared_error: 0.0169\n",
      "Epoch 49/150\n",
      "1412/1412 - 20s - loss: 0.1126 - mean_squared_error: 0.0110 - val_loss: 0.1374 - val_mean_squared_error: 0.0144\n",
      "Epoch 50/150\n",
      "1412/1412 - 20s - loss: 0.1113 - mean_squared_error: 0.0108 - val_loss: 0.1367 - val_mean_squared_error: 0.0146\n",
      "Epoch 51/150\n",
      "1412/1412 - 20s - loss: 0.1109 - mean_squared_error: 0.0107 - val_loss: 0.1431 - val_mean_squared_error: 0.0173\n",
      "Epoch 52/150\n",
      "1412/1412 - 21s - loss: 0.1116 - mean_squared_error: 0.0110 - val_loss: 0.1363 - val_mean_squared_error: 0.0139\n",
      "Epoch 53/150\n",
      "1412/1412 - 20s - loss: 0.1113 - mean_squared_error: 0.0109 - val_loss: 0.1415 - val_mean_squared_error: 0.0164\n",
      "Epoch 54/150\n",
      "1412/1412 - 20s - loss: 0.1108 - mean_squared_error: 0.0107 - val_loss: 0.1462 - val_mean_squared_error: 0.0183\n",
      "Epoch 55/150\n",
      "1412/1412 - 20s - loss: 0.1114 - mean_squared_error: 0.0110 - val_loss: 0.1365 - val_mean_squared_error: 0.0145\n",
      "Epoch 56/150\n",
      "1412/1412 - 21s - loss: 0.1101 - mean_squared_error: 0.0107 - val_loss: 0.1359 - val_mean_squared_error: 0.0144\n",
      "Epoch 57/150\n",
      "1412/1412 - 20s - loss: 0.1101 - mean_squared_error: 0.0108 - val_loss: 0.1388 - val_mean_squared_error: 0.0142\n",
      "Epoch 58/150\n",
      "1412/1412 - 20s - loss: 0.1101 - mean_squared_error: 0.0108 - val_loss: 0.1401 - val_mean_squared_error: 0.0156\n",
      "Epoch 59/150\n",
      "1412/1412 - 20s - loss: 0.1093 - mean_squared_error: 0.0105 - val_loss: 0.1424 - val_mean_squared_error: 0.0159\n",
      "Epoch 60/150\n",
      "1412/1412 - 20s - loss: 0.1093 - mean_squared_error: 0.0105 - val_loss: 0.1359 - val_mean_squared_error: 0.0141\n",
      "Epoch 61/150\n",
      "1412/1412 - 20s - loss: 0.1093 - mean_squared_error: 0.0107 - val_loss: 0.1388 - val_mean_squared_error: 0.0162\n",
      "Epoch 62/150\n",
      "1412/1412 - 20s - loss: 0.1083 - mean_squared_error: 0.0105 - val_loss: 0.1452 - val_mean_squared_error: 0.0181\n",
      "Epoch 63/150\n",
      "1412/1412 - 20s - loss: 0.1092 - mean_squared_error: 0.0107 - val_loss: 0.1362 - val_mean_squared_error: 0.0145\n",
      "Epoch 64/150\n",
      "1412/1412 - 20s - loss: 0.1080 - mean_squared_error: 0.0105 - val_loss: 0.1387 - val_mean_squared_error: 0.0161\n",
      "Epoch 65/150\n",
      "1412/1412 - 20s - loss: 0.1082 - mean_squared_error: 0.0106 - val_loss: 0.1398 - val_mean_squared_error: 0.0152\n",
      "Epoch 66/150\n",
      "1412/1412 - 20s - loss: 0.1082 - mean_squared_error: 0.0105 - val_loss: 0.1381 - val_mean_squared_error: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/150\n",
      "1412/1412 - 20s - loss: 0.1080 - mean_squared_error: 0.0105 - val_loss: 0.1390 - val_mean_squared_error: 0.0161\n",
      "Epoch 68/150\n",
      "1412/1412 - 20s - loss: 0.1075 - mean_squared_error: 0.0105 - val_loss: 0.1372 - val_mean_squared_error: 0.0145\n",
      "Epoch 69/150\n",
      "1412/1412 - 20s - loss: 0.1073 - mean_squared_error: 0.0104 - val_loss: 0.1437 - val_mean_squared_error: 0.0178\n",
      "Epoch 70/150\n",
      "1412/1412 - 20s - loss: 0.1076 - mean_squared_error: 0.0106 - val_loss: 0.1376 - val_mean_squared_error: 0.0147\n",
      "Epoch 71/150\n",
      "1412/1412 - 20s - loss: 0.1069 - mean_squared_error: 0.0104 - val_loss: 0.1383 - val_mean_squared_error: 0.0157\n",
      "Epoch 72/150\n",
      "1412/1412 - 20s - loss: 0.1063 - mean_squared_error: 0.0103 - val_loss: 0.1378 - val_mean_squared_error: 0.0142\n",
      "Epoch 73/150\n",
      "1412/1412 - 20s - loss: 0.1066 - mean_squared_error: 0.0104 - val_loss: 0.1365 - val_mean_squared_error: 0.0142\n",
      "Epoch 74/150\n",
      "1412/1412 - 20s - loss: 0.1066 - mean_squared_error: 0.0103 - val_loss: 0.1362 - val_mean_squared_error: 0.0148\n",
      "Epoch 75/150\n",
      "1412/1412 - 20s - loss: 0.1063 - mean_squared_error: 0.0104 - val_loss: 0.1363 - val_mean_squared_error: 0.0144\n",
      "Epoch 76/150\n",
      "1412/1412 - 20s - loss: 0.1060 - mean_squared_error: 0.0104 - val_loss: 0.1386 - val_mean_squared_error: 0.0161\n",
      "Epoch 77/150\n",
      "1412/1412 - 20s - loss: 0.1056 - mean_squared_error: 0.0103 - val_loss: 0.1378 - val_mean_squared_error: 0.0151\n",
      "Epoch 78/150\n",
      "1412/1412 - 20s - loss: 0.1057 - mean_squared_error: 0.0102 - val_loss: 0.1391 - val_mean_squared_error: 0.0155\n",
      "Epoch 79/150\n",
      "1412/1412 - 20s - loss: 0.1051 - mean_squared_error: 0.0102 - val_loss: 0.1388 - val_mean_squared_error: 0.0159\n",
      "Epoch 80/150\n",
      "1412/1412 - 20s - loss: 0.1055 - mean_squared_error: 0.0102 - val_loss: 0.1369 - val_mean_squared_error: 0.0143\n",
      "Epoch 81/150\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1412/1412 - 20s - loss: 0.1053 - mean_squared_error: 0.0103 - val_loss: 0.1400 - val_mean_squared_error: 0.0151\n",
      "Epoch 82/150\n",
      "1412/1412 - 20s - loss: 0.1039 - mean_squared_error: 0.0100 - val_loss: 0.1364 - val_mean_squared_error: 0.0147\n",
      "Epoch 83/150\n",
      "1412/1412 - 20s - loss: 0.1031 - mean_squared_error: 0.0099 - val_loss: 0.1363 - val_mean_squared_error: 0.0146\n",
      "Epoch 84/150\n",
      "1412/1412 - 20s - loss: 0.1029 - mean_squared_error: 0.0099 - val_loss: 0.1360 - val_mean_squared_error: 0.0148\n",
      "Epoch 85/150\n",
      "1412/1412 - 20s - loss: 0.1027 - mean_squared_error: 0.0099 - val_loss: 0.1362 - val_mean_squared_error: 0.0146\n",
      "Epoch 86/150\n",
      "1412/1412 - 20s - loss: 0.1025 - mean_squared_error: 0.0098 - val_loss: 0.1377 - val_mean_squared_error: 0.0152\n",
      "Epoch 87/150\n",
      "1412/1412 - 20s - loss: 0.1024 - mean_squared_error: 0.0098 - val_loss: 0.1369 - val_mean_squared_error: 0.0149\n",
      "Epoch 88/150\n",
      "1412/1412 - 20s - loss: 0.1023 - mean_squared_error: 0.0098 - val_loss: 0.1370 - val_mean_squared_error: 0.0153\n",
      "Epoch 89/150\n",
      "1412/1412 - 20s - loss: 0.1022 - mean_squared_error: 0.0098 - val_loss: 0.1367 - val_mean_squared_error: 0.0149\n",
      "Epoch 90/150\n",
      "1412/1412 - 20s - loss: 0.1020 - mean_squared_error: 0.0098 - val_loss: 0.1359 - val_mean_squared_error: 0.0144\n",
      "Epoch 91/150\n",
      "1412/1412 - 20s - loss: 0.1019 - mean_squared_error: 0.0098 - val_loss: 0.1383 - val_mean_squared_error: 0.0158\n",
      "Epoch 92/150\n",
      "1412/1412 - 20s - loss: 0.1018 - mean_squared_error: 0.0098 - val_loss: 0.1375 - val_mean_squared_error: 0.0153\n",
      "Epoch 93/150\n",
      "1412/1412 - 20s - loss: 0.1018 - mean_squared_error: 0.0098 - val_loss: 0.1371 - val_mean_squared_error: 0.0151\n",
      "Epoch 94/150\n",
      "1412/1412 - 20s - loss: 0.1017 - mean_squared_error: 0.0098 - val_loss: 0.1374 - val_mean_squared_error: 0.0152\n",
      "Epoch 95/150\n",
      "1412/1412 - 20s - loss: 0.1015 - mean_squared_error: 0.0098 - val_loss: 0.1379 - val_mean_squared_error: 0.0155\n",
      "Epoch 96/150\n"
     ]
    }
   ],
   "source": [
    "\"\"\" CUPNET TRAINING \"\"\"\n",
    "CUPNET_history = CUPNET.fit(MX_train, My_train,\n",
    "          batch_size = 32,epochs= 150,\n",
    "          verbose=2,validation_data=(MX_test,My_test),callbacks=[reduce_lr,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUPNET.save_weights(\"../../data/model_stuff/cupnet_model_weights_4_23.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = CUPNET.predict(MX_train)\n",
    "y_test_pred = CUPNET.predict(MX_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video(y_train_pred,MX_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File(hdf5_dir / f\"u_net_predict.h5\", \"w\")\n",
    "dataset = file.create_dataset(\"images\",np.shape(y_test_pred),h5py.h5t.STD_U8BE,data=y_test_pred)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_many_hdf5(images,name):\n",
    "\n",
    "    num_images = len(images)\n",
    "    try:\n",
    "        os.mkdir(\"../../data/hdf5\")\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "    # Create a new HDF5 file\n",
    "    file = h5py.File(hdf5_dir / f\"{name}_vids.h5\", \"w\")\n",
    "\n",
    "    # Create a dataset in the file\n",
    "    dataset = file.create_dataset(\n",
    "        \"images\", data=images\n",
    "    )    \n",
    "    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../data/hdf5/u_net_test_ims\",y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_many_hdf5(y_test_pred,\"u_net_predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "twist_jelly = sio.loadmat('../../data/hdf5/jelly_resized.mat')\n",
    "jelly = np.asarray(twist_jelly['sample'])\n",
    "jelly = np.transpose(jelly,(2,0,1))\n",
    "jelly = np.reshape(jelly[30:60], (1,30,32,32,1))\n",
    "print(np.shape(jelly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_pred = CUPNET.predict(jelly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
