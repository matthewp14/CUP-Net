{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Feb 26 17:01:56 2020\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" IMPORTS \"\"\"\n",
    "import sys\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.constraints import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "from binary_ops import binary_tanh as binary_tanh_op\n",
    "from binary_layers import BinaryDense, BinaryConv2D\n",
    "\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from lambda_layers import *\n",
    "from binary_ops import *\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 62, 32, 1)\n",
      "(560, 62, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" FUNCTIION AND VARIABLE DEFINITIONS \"\"\"\n",
    "def binary_tanh(x):\n",
    "    return binary_tanh_op(x)\n",
    "\n",
    "H = 1.\n",
    "kernel_lr_multiplier = 'Glorot'\n",
    "\n",
    "# # nn\n",
    "batch_size = 50\n",
    "epochs = 20\n",
    "channels = 1\n",
    "img_rows = 30\n",
    "img_cols = 30\n",
    "filters = 32\n",
    "kernel_size = (32, 32)\n",
    "pool_size = (2, 2)\n",
    "hidden_units = 128\n",
    "classes = 10\n",
    "use_bias = False\n",
    "\n",
    "# # learning rate schedule\n",
    "lr_start = 1e-3\n",
    "lr_end = 1e-4\n",
    "lr_decay = (lr_end / lr_start)**(1. / epochs)\n",
    "\n",
    "# # BN\n",
    "epsilon = 1e-6\n",
    "momentum = 0.9\n",
    "\n",
    "# # dropout\n",
    "p1 = 0.25\n",
    "p2 = 0.5\n",
    "\n",
    "hdf5_dir = Path(\"../data/hdf5/\")\n",
    "\n",
    "def read_many_hdf5(num_images):\n",
    "    \"\"\" Reads image from HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    images= []\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    file = h5py.File(hdf5_dir / f\"{num_images}_vids.h5\", \"r+\")\n",
    "\n",
    "    images = np.array(file[\"/images\"]).astype(\"float32\")\n",
    "\n",
    "    return images\n",
    "\n",
    "def np_streak(x):\n",
    "    input_dims = np.shape(x)\n",
    "    output_shape = (input_dims[0],input_dims[1],input_dims[1]+input_dims[2],input_dims[3],input_dims[4])\n",
    "    streak_tensor = np.zeros(output_shape)\n",
    "    for i in range(output_shape[0]):\n",
    "        for j in range(output_shape[1]):\n",
    "            streak_tensor[i,j,j:(output_shape[3]+j),:,:] = x[i,j,:,:,:]\n",
    "    #return streak_tensor\n",
    "    return np.sum(streak_tensor,axis=1)\n",
    "\n",
    "def mask(val,ims,mask):\n",
    "    for i in range(np.shape(val)[0]):\n",
    "        for j in range(np.shape(val)[1]):\n",
    "            val[i,j,:,:] = ims[i,j,:,:] * mask\n",
    "    return val\n",
    "\n",
    "\n",
    "\n",
    "ims = read_many_hdf5(859)\n",
    "# ims = np.ones((3943,30,32,32,1))\n",
    "ims = np.reshape(ims, (-1,30,32,32,1))\n",
    "ims = ims[:840]\n",
    "# temp = np.zeros((1,32,32,1))\n",
    "validate2 = np.zeros((840,30,32,32,1))\n",
    "bk_temp = np.random.randint(0,2,(1,32,32,1))\n",
    "validate2 = mask(validate2,ims,bk_temp)\n",
    "ims2 = np_streak(validate2)\n",
    "\n",
    "\n",
    "validate = ims\n",
    "\n",
    "validate = validate / 255\n",
    "ims2 = ims2 /255\n",
    "ims = ims/255\n",
    "#X_train, X_test, y_train, y_test = train_test_split(ims, validate, test_size=(1/3), random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ims2, validate, test_size=(1/3), random_state=42)\n",
    "\n",
    "MX_train, MX_test, My_train, My_test = train_test_split(ims,ims, test_size = 1/3, random_state = 42)\n",
    "\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(X_train))\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',verbose=1, factor=0.5,\n",
    "                              patience=50, min_lr=0.000001)\n",
    "early_stopping = EarlyStopping(patience=90,verbose=1,restore_best_weights=True)   \n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "\n",
    "  ssim_loss = (1.0-tf.image.ssim(y_true,y_pred,1))/2.0\n",
    "  mse_loss = K.mean(K.square(y_pred-y_true))\n",
    "  #mse_loss = tf.keras.losses.mean_squared_error(y_true,y_pred)\n",
    "\n",
    "  ssim_loss = 0.5*ssim_loss\n",
    "  mse_loss = 0.5*mse_loss\n",
    "\n",
    "  return ssim_loss + mse_loss\n",
    "\n",
    "def ssim_loss(y_true,y_pred):  \n",
    "    return (1.0-tf.image.ssim(y_true,y_pred,1))/2.0\n",
    "\n",
    "def mse_loss(y_true,y_pred):\n",
    "    return K.mean(K.square(y_pred-y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" VIDEO FUNCTIONS FOR CHECKING POST TRAINING\"\"\"\n",
    "\n",
    "def get_mask(model,l=0):\n",
    "    b = binarize(model.layers[l].weights[0])\n",
    "    figb,axb = plt.subplots(1,1)\n",
    "    axb.imshow(np.reshape(b,(32,32)),cmap=\"gray\")\n",
    "    \n",
    "def show_video(y_pred,y_true,num):\n",
    "    yp = np.reshape(y_pred,(-1,30,32,32))\n",
    "    yt = np.reshape(y_true,(-1,30,32,32))\n",
    "    fig,ax = plt.subplots(nrows=5,ncols=6,sharex=True,sharey=True)\n",
    "    fig2,ax2 = plt.subplots(nrows=5,ncols=6,sharex=True,sharey=True)\n",
    "    for row in range(5):\n",
    "        for col in range(6):\n",
    "            ax[row,col].imshow(yp[num][5*row+col],cmap=\"gray\")\n",
    "            ax2[row,col].imshow(yt[num][5*row+col],cmap=\"gray\")\n",
    "\n",
    "def show_all_videos(videos,rows,cols):\n",
    "    yp = np.reshape(videos, (-1,30,32,32))\n",
    "    fix3,ax3 = plt.subplots(nrows=rows, ncols = cols)\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            ax3[row,col].imshow(yp[rows*row+col][3],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_2 (TimeDist (40, 30, 32, 32, 1)       1024      \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (40, 30, 62, 32, 1)       0         \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (40, 62, 32, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (40, 1984)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (40, 30720)               60979200  \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (40, 30, 32, 32, 1)       0         \n",
      "=================================================================\n",
      "Total params: 60,980,224\n",
      "Trainable params: 60,980,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 560 samples, validate on 280 samples\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: input_iterator:0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-32224c105407>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m forward_history = forward_model.fit(MX_train, My_train,\n\u001b[0;32m     17\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m           verbose=2,validation_data=(MX_test,My_test),callbacks=[reduce_lr, early_stopping])\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     74\u001b[0m           \u001b[1;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m           \"tensors, but found {}\".format(keras_symbolic_tensors))\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\CUPNET\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: input_iterator:0"
     ]
    }
   ],
   "source": [
    "\"\"\" FORWARD MODEL \"\"\"\n",
    "\n",
    "forward_model = Sequential()\n",
    "forward_model.add(Input(shape=(30,32,32,1),batch_size = 40))\n",
    "forward_model.add(TimeDistributed(BinaryConv2D(1, kernel_size=(32,32), input_shape=(30,32,32,1),\n",
    "                       data_format='channels_last',\n",
    "                       H=H, kernel_lr_multiplier=kernel_lr_multiplier,\n",
    "                       padding='same', use_bias=use_bias, name='bin_conv_1')))\n",
    "forward_model.add(Lambda(streak,output_shape=streak_output_shape))\n",
    "forward_model.add(Lambda(integrate_ims, output_shape = integrate_ims_output_shape))\n",
    "forward_model.add(Flatten())\n",
    "forward_model.add(Dense(30720, activation = 'relu'))\n",
    "forward_model.add(Reshape((30,32,32,1)))\n",
    "forward_model.compile(optimizer = Nadam(0.0001), loss = custom_loss, metrics = ['mean_squared_error',mse_loss])\n",
    "forward_model.summary()\n",
    "forward_history = forward_model.fit(MX_train, My_train,\n",
    "          batch_size = 40,epochs= 500,\n",
    "          verbose=2,validation_data=(MX_test,My_test),callbacks=[reduce_lr, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_12 (TimeDis (40, 30, 32, 32, 1)       1024      \n",
      "_________________________________________________________________\n",
      "lambda_24 (Lambda)           (40, 30, 62, 32, 1)       0         \n",
      "_________________________________________________________________\n",
      "lambda_25 (Lambda)           (40, 62, 32, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (40, 1984)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (40, 30720)               60979200  \n",
      "_________________________________________________________________\n",
      "reshape_12 (Reshape)         (40, 30, 32, 32, 1)       0         \n",
      "=================================================================\n",
      "Total params: 60,980,224\n",
      "Trainable params: 60,980,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 560 samples, validate on 280 samples\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fine Tuning Parameters: \n",
    "Ratio between MSE and SSIM \n",
    "\"\"\"\n",
    "\n",
    "ssim_alpha = 0.1\n",
    "ssim_beta = 0.9\n",
    "def variable_custom_loss(y_true, y_pred):\n",
    "    global ssim_alpha, ssim_beta\n",
    "    ssim_loss = (1.0-tf.image.ssim(y_true,y_pred,1))/2.0\n",
    "    mse_loss = K.mean(K.square(y_pred-y_true))\n",
    "    #mse_loss = tf.keras.losses.mean_squared_error(y_true,y_pred)\n",
    "\n",
    "    ssim_loss = ssim_alpha*ssim_loss\n",
    "    mse_loss = ssim_beta*mse_loss\n",
    "\n",
    "\n",
    "alpha = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "beta = [0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1]\n",
    "\n",
    "mse_losses = []\n",
    "ssim_losses = []\n",
    "mse_sd = []\n",
    "ssim_sd = []\n",
    "\n",
    "for i in range(9):\n",
    "    ssim_alpha = alpha[i]\n",
    "    ssim_beta = beta[i]\n",
    "    inner_mse_losses=[]\n",
    "    inner_ssim_losses=[]\n",
    "    for j in range(10):\n",
    "        MX_train, MX_test, My_train, My_test = train_test_split(ims,ims, test_size = 1/3)\n",
    "        forward_model = Sequential()\n",
    "        forward_model.add(Input(shape=(30,32,32,1),batch_size = 40))\n",
    "        forward_model.add(TimeDistributed(BinaryConv2D(1, kernel_size=(32,32), input_shape=(30,32,32,1),\n",
    "                           data_format='channels_last',\n",
    "                           H=H, kernel_lr_multiplier=kernel_lr_multiplier,\n",
    "                           padding='same', use_bias=use_bias, name='bin_conv_1')))\n",
    "        forward_model.add(Lambda(streak,output_shape=streak_output_shape))\n",
    "        forward_model.add(Lambda(integrate_ims, output_shape = integrate_ims_output_shape))\n",
    "        forward_model.add(Flatten())\n",
    "        forward_model.add(Dense(30720, activation = 'relu'))\n",
    "        forward_model.add(Reshape((30,32,32,1)))\n",
    "        forward_model.compile(optimizer = Nadam(0.0001), loss = custom_loss, metrics = ['mean_squared_error',ssim_loss])\n",
    "        forward_model.summary()\n",
    "        forward_history = forward_model.fit(MX_train, My_train,\n",
    "              batch_size = 40,epochs= 1,\n",
    "              verbose=2,validation_data=(MX_test,My_test),callbacks=[reduce_lr])\n",
    "        evals = forward_model.evaluate(MX_test,My_test)\n",
    "        inner_mse_losses.append(evals[1])\n",
    "        inner_ssim_losses.append(evals[2])\n",
    "    mse_losses.append(np.mean(inner_mse_losses))\n",
    "    ssim_losses.append(np.mean(inner_ssim_losse))\n",
    "    mse_sd.append(np.std(inner_mse_losses))\n",
    "    ssim_sd.append(np.std(inner_ssim_losses))\n",
    "\n",
    "\n",
    "with (\"training_logs.txt\",'w') as file:\n",
    "    for i in range(10):\n",
    "        file.write(\"[ssim,mse]: \" + \"[\"+str(alpha[i])+\",\"+str(beta[i])+\"]\"+ \"MSE LOSS: \" + str(mse_losses[i]) + \" +/- \" + str(mse_sd[i]) + + \" SSIM LOSS: \" + str(ssim_losses[i]) + \" +/- \" + str(ssim_sd[i]) + \"\\n\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ssim = model.predict(MX_train)\n",
    "y_pred_ssim = tf.convert_to_tensor(y_pred_ssim)\n",
    "y_true_ssim = tf.convert_to_tensor(My_train)\n",
    "\n",
    "print(\"AVG SSIM: \" + str(ssim_loss(y_pred_ssim, y_true_ssim).numpy().mean()))\n",
    "print(\"AVG MSE: \" + str(mse_loss(y_pred_ssim,y_true_ssim).numpy().mean()))\n",
    "## sanity check\n",
    "\n",
    "o = tf.convert_to_tensor(np.ones((30,30,1)))\n",
    "z = tf.convert_to_tensor(np.zeros((30,30,1)))\n",
    "ssim_loss(o,z)\n",
    "tf.image.ssim(o,z,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for x in range(10):\n",
    "    i += 1\n",
    "    for z in range(10):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
